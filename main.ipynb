{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elahekarimi/stt/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZorNve1D5ZY",
        "outputId": "edfc70af-f464-4568-a75d-9501c5b99eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchaudio) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchaudio) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "['zcrm_1928433000860261621', 'zcrm_1928433000857205263', 'zcrm_1928433000854862161']\n",
            "['https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/REd98677cba2ae998d53c5dc34d2f40a4d.mp3', 'https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/REdfda04ba2e9117867fce59bbd9c3db0f.mp3', 'https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/RE3286fb2601a3d8c1b6124b5d80483a90.mp3']\n"
          ]
        }
      ],
      "source": [
        "#@title list of mp3 files\n",
        "!pip3 install pandas\n",
        "!pip3 install onnx \n",
        "!pip3 install omegaconf\n",
        "!pip3 install torchaudio\n",
        "!pip install onnxruntime\n",
        "import pandas as pd\n",
        "import random\n",
        "csv_file_path = '/content/en_calls.csv'\n",
        "df = pd.read_csv(csv_file_path, header=None, names=['CALLID', 'Call Duration', 'Call Start Time', 'Call Type', 'Description'])\n",
        "\n",
        "# Extract CALLID and Description columns from the DataFrame\n",
        "callid_col = df[\"CALLID\"]\n",
        "description_col = df[\"Description\"]\n",
        "\n",
        "# Choose 5 random indices\n",
        "random_indices = callid_col.sample(n=3, random_state=random.seed()).index\n",
        "\n",
        "# Initialize lists to store CALLIDs and Descriptions\n",
        "list_callids = []\n",
        "list_english_url = []\n",
        "\n",
        "# Loop through the random indices\n",
        "for index in random_indices:\n",
        "    callid = callid_col.iloc[index]\n",
        "    description = description_col.iloc[index]\n",
        "    if not pd.isnull(callid):\n",
        "        list_callids.append(callid)\n",
        "        list_english_url.append(description)\n",
        "\n",
        "print(list_callids)\n",
        "print(list_english_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YzgCUn5EdPc",
        "outputId": "8bfbc7e4-a906-45ff-b788-fbfebb940044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/RE7b388c4ef6a2427f4840c04512e0f691.mp3', 'https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/RE1be713429eee9f075f7eca232137696d.mp3', 'https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/REa3e7acd6177afb7ed2c91e92247a43b1.mp3']\n",
            "['zcrm_1928433001077811279', 'zcrm_1928433001081505357', 'zcrm_1928433001101605243']\n"
          ]
        }
      ],
      "source": [
        "#@title audio files (Arabic)\n",
        "csv_file_path = '/content/calls-AR.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "url_col = df[\"Description\"]\n",
        "\n",
        "# Choose 3 random rows\n",
        "random_rows = url_col.sample(n=3, random_state=random.seed())\n",
        "\n",
        "list_url = []\n",
        "list_call_duration = []\n",
        "\n",
        "# Loop through the random rows\n",
        "for url in random_rows:\n",
        "    if url != 'nan':\n",
        "        list_url.append(url)\n",
        "        # Get corresponding Call Duration for the selected row\n",
        "        callid = df.loc[df['Description'] == url, 'CALLID'].iloc[0]\n",
        "        list_call_duration.append(callid)\n",
        "\n",
        "print(list_url)\n",
        "print(list_call_duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJzqLixhEfwd",
        "outputId": "3caf5577-af3d-4433-b543-760d6ce27075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/RE18ee1861762b1b78e6ca609327c7d346.mp3', 'https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/RE3b7af4b7bfe8ddf8137b78720ddb0ffe.mp3', 'https://api.twilio.com/2010-04-01/Accounts/AC935e4741269cf93dab70dbea560439ea/Recordings/RE107232b07b98de2cf6eac1a40e8233d9.mp3']\n",
            "['zcrm_1928433001091243284', 'zcrm_1928433001090019805', 'zcrm_1928433001089674201']\n"
          ]
        }
      ],
      "source": [
        "#@title audio files (Turkish)\n",
        "csv_file_path = '/content/calls-TR.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "url_col = df[\"Description\"]\n",
        "\n",
        "# Choose 3 random rows\n",
        "random_rows = url_col.sample(n=3, random_state=random.seed())\n",
        "\n",
        "list_tur = []\n",
        "list_tr_call = []\n",
        "\n",
        "# Loop through the random rows\n",
        "for url in random_rows:\n",
        "    if url != 'nan':\n",
        "        list_tur.append(url)\n",
        "        # Get corresponding Call Duration for the selected row\n",
        "        callid = df.loc[df['Description'] == url, 'CALLID'].iloc[0]\n",
        "        list_tr_call.append(callid)\n",
        "\n",
        "print(list_tur)\n",
        "print(list_tr_call)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHMD0drOEM9c",
        "outputId": "c864a61b-0593-44b9-9b44-f0f403fd27b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/snakers4/silero-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "100%|██████████| 112M/112M [00:04<00:00, 24.9MB/s]\n",
            "100%|██████████| 28.6k/28.6k [00:00<00:00, 20.1MB/s]\n",
            "100%|██████████| 112M/112M [00:04<00:00, 25.1MB/s]\n",
            "1.47MB [00:03, 496kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "think this is a mean i'm you from of can clin regard in your al qui with us yes yes or i want you actually qu you have something specific in the mind or you actually have fu concentitation go what treatment plan work better like to because jo bres which actually one completely so want to like that for the s coming c plants say the the jo that still health but that same so to the in pl well i like actually have the c for ities very very very big actually treatments for for for jo ok and regard in the other health you put your on the well yes call c yes coming cs think king think for or want to comp see i actually one in plants don if you are the str plants or don'tknow just comm strong on plants so think about proble but other plants which got or factcess be be like work the b i can think well about difference any different brass but for the moment i my know is the the str on is option yes ct actually the strong is the best opt that exist in whole mar actually but bigigma it' quite and most people actually go to the ic ma because it's quite is different in the pr between strong and and migma for the single implants for the strong and is whatonce thousand for hundred other but in the migma the ger one of course ' course five hundred do so is a quite big differentdifference in those not the mig actually really good just a difference of of course the strong is way better than the midig course so and on your ud of course you know how many impl you need like for plants that like impl 's going to very big oun of different money the difference which between the strong and the migam it' going to be a very big difference ing so i i like to different upptions to have b to choose like the option for just come like price and the qual ity would like to to compare was differen in the price ok so can do is i s you misses so what's up some ach that we need from you ong that i have sent you the picture and your case then pend those 'm going es and can actually give the fu treatment pl for both igma strong and then you can actually choose ever which one or okay so i should you pictures yes if you have p actually that be better could you down ma like that i sen email this pictures because in the p d file is you pictures one file prefer sure i actually send you whats up msageif you want s the the and pict can or what's up and i got only on the byso have to just trans the f more i if you if like end you ma for for the moment to the email 'm going to do is i i ready you whats up it you for communicate but i ication ok ay but the email it will for in from you okay ictions ay right so do that and communication can what's up i have sent you both any and what'supand i would do you or you ta look look yes look it was pl you would you ach think you thank you much i for that good day think i\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1.00MB [00:02, 510kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lo even or have about your someor yeah you very much my name is mean 'm call you from clinic gu in trans so you qu in for the transant qu for yourself for some one that you know about me you right how you money nine see to be the problem with the because quite frly young have problem yeah just just for just grwn and i four whatever you all just just going and how all in since you al twent well you from or from ind here so you you well yeah so that actually maybe the reason because the change the whether area that you live maybe work maybe well work not have mean the is especially you know when you change the place you maybe some stress or lot and do you more good drink goation sometimes you have any chronic diseases or others you you me lo you ar me sorry problem my like that sound actually if you have any chronic other you you not have you any pre vious perations one question regard the help ple currently are you take in any medication you alth or sorry completely got you is and day have you been to talk you before you have not or right and when are you plan on come for trans much bab and february not let me just send you next ep messa for what going s actually icture give you idea how want pictures to be ta take it from okay or a good thank but\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1.13MB [00:02, 447kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes good mor yes my name year yes you from your kind i yes numberber just and yes procedure you like to have like kind a okay know venty eight is i still have my but ro like yes and what ever cre you have may be i don't know what for the to for all my ok so need some phone of you te you have what what number another number i find you what' number we have what doctor formation would kind so you and some phone yes i can s you and exthree that i have and you have to lect to procedure that get body to the te okay i think ' yes i think ok and i can i can i can come december or this year or i can come next year i would i would need i would need log to have some phones of to come from what doctor and if you can end me pure like what now so to i ure be more eas you know i have exthree the and i s copy or to gr and s and then if it' not supicion do something that' time okay or right so what would be better i december or next year deceber whatever what for you like you need to what the doctor day and you will know okay and i'd like to know long the procedure is and to go and the course log oldso you and me or and dece okay is it easy to get from the a ok there do there to or number when an a want europe sideso i i d be f from your yes so i go to the youruroan side so for you i i know european side eas may be it' so have of there another or and little bit for okay so just s the picture to your number yes i yes receing your phone phone you for more ay thank you you what is your name love sp i you can call and okay that's gr son name yes can you put you name or what i and it just only you and what ok is my name is and there okay very good so i get today i think right is l l tomor or right know from thank you but\n",
            "[\"think this is a mean i'm you from of can clin regard in your al qui with us yes yes or i want you actually qu you have something specific in the mind or you actually have fu concentitation go what treatment plan work better like to because jo bres which actually one completely so want to like that for the s coming c plants say the the jo that still health but that same so to the in pl well i like actually have the c for ities very very very big actually treatments for for for jo ok and regard in the other health you put your on the well yes call c yes coming cs think king think for or want to comp see i actually one in plants don if you are the str plants or don'tknow just comm strong on plants so think about proble but other plants which got or factcess be be like work the b i can think well about difference any different brass but for the moment i my know is the the str on is option yes ct actually the strong is the best opt that exist in whole mar actually but bigigma it' quite and most people actually go to the ic ma because it's quite is different in the pr between strong and and migma for the single implants for the strong and is whatonce thousand for hundred other but in the migma the ger one of course ' course five hundred do so is a quite big differentdifference in those not the mig actually really good just a difference of of course the strong is way better than the midig course so and on your ud of course you know how many impl you need like for plants that like impl 's going to very big oun of different money the difference which between the strong and the migam it' going to be a very big difference ing so i i like to different upptions to have b to choose like the option for just come like price and the qual ity would like to to compare was differen in the price ok so can do is i s you misses so what's up some ach that we need from you ong that i have sent you the picture and your case then pend those 'm going es and can actually give the fu treatment pl for both igma strong and then you can actually choose ever which one or okay so i should you pictures yes if you have p actually that be better could you down ma like that i sen email this pictures because in the p d file is you pictures one file prefer sure i actually send you whats up msageif you want s the the and pict can or what's up and i got only on the byso have to just trans the f more i if you if like end you ma for for the moment to the email 'm going to do is i i ready you whats up it you for communicate but i ication ok ay but the email it will for in from you okay ictions ay right so do that and communication can what's up i have sent you both any and what'supand i would do you or you ta look look yes look it was pl you would you ach think you thank you much i for that good day think i\", \"lo even or have about your someor yeah you very much my name is mean 'm call you from clinic gu in trans so you qu in for the transant qu for yourself for some one that you know about me you right how you money nine see to be the problem with the because quite frly young have problem yeah just just for just grwn and i four whatever you all just just going and how all in since you al twent well you from or from ind here so you you well yeah so that actually maybe the reason because the change the whether area that you live maybe work maybe well work not have mean the is especially you know when you change the place you maybe some stress or lot and do you more good drink goation sometimes you have any chronic diseases or others you you me lo you ar me sorry problem my like that sound actually if you have any chronic other you you not have you any pre vious perations one question regard the help ple currently are you take in any medication you alth or sorry completely got you is and day have you been to talk you before you have not or right and when are you plan on come for trans much bab and february not let me just send you next ep messa for what going s actually icture give you idea how want pictures to be ta take it from okay or a good thank but\", \"yes good mor yes my name year yes you from your kind i yes numberber just and yes procedure you like to have like kind a okay know venty eight is i still have my but ro like yes and what ever cre you have may be i don't know what for the to for all my ok so need some phone of you te you have what what number another number i find you what' number we have what doctor formation would kind so you and some phone yes i can s you and exthree that i have and you have to lect to procedure that get body to the te okay i think ' yes i think ok and i can i can i can come december or this year or i can come next year i would i would need i would need log to have some phones of to come from what doctor and if you can end me pure like what now so to i ure be more eas you know i have exthree the and i s copy or to gr and s and then if it' not supicion do something that' time okay or right so what would be better i december or next year deceber whatever what for you like you need to what the doctor day and you will know okay and i'd like to know long the procedure is and to go and the course log oldso you and me or and dece okay is it easy to get from the a ok there do there to or number when an a want europe sideso i i d be f from your yes so i go to the youruroan side so for you i i know european side eas may be it' so have of there another or and little bit for okay so just s the picture to your number yes i yes receing your phone phone you for more ay thank you you what is your name love sp i you can call and okay that's gr son name yes can you put you name or what i and it just only you and what ok is my name is and there okay very good so i get today i think right is l l tomor or right know from thank you but\"]\n"
          ]
        }
      ],
      "source": [
        "#@title audio to text (English)\n",
        "import onnx\n",
        "import torch\n",
        "import onnx\n",
        "import onnxruntime\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "text_list = []\n",
        "\n",
        "language = 'en' # also available 'de', 'es'\n",
        "\n",
        "# load provided utils\n",
        "_, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_stt', language=language)\n",
        "(read_batch, split_into_batches,\n",
        " read_audio, prepare_model_input) = utils\n",
        "\n",
        " # see available models\n",
        "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml', 'models.yml')\n",
        "models = OmegaConf.load('models.yml')\n",
        "available_languages = list(models.stt_models.keys())\n",
        "assert language in available_languages\n",
        "\n",
        "# load the actual ONNX model\n",
        "torch.hub.download_url_to_file(models.stt_models.en.latest.onnx, 'model.onnx', progress=True)\n",
        "onnx_model = onnx.load('model.onnx')\n",
        "onnx.checker.check_model(onnx_model)\n",
        "ort_session = onnxruntime.InferenceSession('model.onnx')\n",
        "\n",
        "# download a single file, any format compatible with TorchAudio\n",
        "for i in list_english_url:\n",
        "    audio_file = pd\n",
        "    torch.hub.download_url_to_file(i, dst ='speech_orig.wav', progress=True)\n",
        "    test_files = ['speech_orig.wav']\n",
        "    batches = split_into_batches(test_files, batch_size=10)\n",
        "    input = prepare_model_input(read_batch(batches[0]))\n",
        "\n",
        "    # actual onnx inference and decoding\n",
        "    onnx_input = input.detach().cpu().numpy()\n",
        "    ort_inputs = {'input': onnx_input}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "    decoded = decoder(torch.Tensor(ort_outs[0])[0])\n",
        "    print(decoded)\n",
        "    text_list.append(decoded)\n",
        "print(text_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwTKTwtgEqgG",
        "outputId": "234752cb-4602-4172-d699-58cfdf83cef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "['الو الو السلام عليكم وعليكم السلام عليكم بالخير و لا خير ان شاء الله الله يخليك معك رضوان اخي الصغير طبي من مستشفى تركيانا اسطنبول تركيا يعني تواصلت معنا مش الموقع تجميليه دوت كوم انك مهتم عمليه تجميل صح هذا على الواتساب قلت له باكر ان شاء الله اقول لك يا عم صحيح صح من اللي شفته بعدنا صح اللي حكى معك صح والله اللي حكى معك مول مارينا انا راح ابعث لك كل شيء على الواتساب بعد لكن شفت بعيني و كل شيء ترى ان شاء الله تمام احنا في اسطنبول الاوروبيه مارينا يعني راح ابعث لك انا لو واحد لوريا اذا بتعرف عليها يعني احنا على البحر يعني بجانب المارينا 32 سنه 32 سنه العمر كله ان شاء الله وتعالى اذا قدر الله السكري ضغط الدم ما عندك ادويه صح ما في اي مشكله ما في اي مشكله وانت رحت ترجعي على اسطنبول ان شاء الله قبل العيد ان شاء الله ما في اي مشكله تمام تمام فهمت عليك ما في اي مشكله تمام انت سجل عندك رقمي باسم رضوان تركي انا مش اذا حكيت معك مره ثانيه ما تعرفني تمام تكون فاضي راح ابعث لك كيف تاخذ الصغار ابعث لك على الواتساب ان تاخذ الصور ابعث لي اياه ان شاء الله ان شاء الله شكرا كثير ومع السلامه مع السلامه', 'الو مرحبا السلام عليكم صار عندك بهمني عارف لحالي عشان اشوفهم واهلي اولا هو عمرك لو سمحت عايزين الاسم الكريم من فضلك عمري 20 سنه جاسم لخالد فارس فارس بدي اعرف ان شاء الله بس ان شاء الله ابعث لي الصور خليني اشوفك اذا ما هل العمليه والا بعطيك كل التفاصيل', 'الو الو السلام عليكم ورحمه الله وبركاته وعليكم السلام في موضوع زراعه الشعر والتجميل والاسنان مستشفى تركيانا اسطنبول والله انا شفت موقعكم انستغرام عندكم عشان اسوي تعديل المفاتيح لا تعمل عمليات اسنان هوليود سمايل في المشاهير لا والله انا عندي فكره ما فهمت عليك طيب اخوي بس شهر احنا بالميلادي لو تكرمت اي شهر ممكن يعني بعد 7 شهور وزاره الصحه من اكثر من 12 سنه مبنى متكامل بيت ام تركي ان شاء الله تحصل على نتائج ممتازه واشعار او اكثر حياك الله استاذ ايمن اسم حضرتك مضغوط اهلا وسهلا فيك وانا اخوك']\n"
          ]
        }
      ],
      "source": [
        "#@title audio to text (Arabic)\n",
        "!pip install SpeechRecognition requests\n",
        "!pip install pydub\n",
        "import os\n",
        "import requests\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to download an audio file from a URL\n",
        "def download_audio_from_url(url, destination_path):\n",
        "    response = requests.get(url)\n",
        "    with open(destination_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "# Function to convert audio file to text\n",
        "def convert_audio_to_text(file_path, language='ar-SA'):\n",
        "    # Initialize the recognizer\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    # Load the audio file\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        # Read the audio data from the file\n",
        "        audio_data = r.record(source)\n",
        "\n",
        "        # Perform speech recognition\n",
        "        text = r.recognize_google(audio_data, language=language)\n",
        "\n",
        "        return text\n",
        "\n",
        "# Function to convert a list of audio files to text\n",
        "def convert_audio_list_to_text(file_list, language='ar-SA'):\n",
        "    texts = []\n",
        "    for file_path in file_list:\n",
        "        text = convert_audio_to_text(file_path, language)\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# List of MP3 files URLs\n",
        "mp3_files = list_url\n",
        "\n",
        "arabic_files = []\n",
        "\n",
        "# Create a directory to save the downloaded files\n",
        "os.makedirs('audio_files', exist_ok=True)\n",
        "\n",
        "# Download the MP3 files\n",
        "downloaded_files = []\n",
        "for index, url in enumerate(mp3_files):\n",
        "    file_path = f'audio_files/audio{index+1}.mp3'\n",
        "    download_audio_from_url(url, file_path)\n",
        "    downloaded_files.append(file_path)\n",
        "\n",
        "# Convert MP3 files to WAV format\n",
        "wav_files = []\n",
        "for index, file_path in enumerate(downloaded_files):\n",
        "    wav_path = f'audio_files/audio{index+1}.wav'\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    audio.export(wav_path, format='wav')\n",
        "    wav_files.append(wav_path)\n",
        "\n",
        "# Convert WAV files to text\n",
        "transcriptions = convert_audio_list_to_text(wav_files, language='ar-SA')\n",
        "\n",
        "# Print the transcriptions\n",
        "for index, transcription in enumerate(transcriptions):\n",
        "    #print(f'Transcription {index+1}: {transcription}')\n",
        "    arabic_files.append(transcription)\n",
        "print(arabic_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I1Fpq4hICKG",
        "outputId": "846d943b-5b6c-485a-8999-8edaa489be19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "['Alo alo sesim geliyor mu acaba 14 cm ortama Tepe bölgesinde nasıl gerçekleşir var bir şey var yani ona göre bir analiz yapalım Siz arayıp detaylı bilgi vereyim ya zaten şey sadece ön taraftan bir tanem çeksem atsam olur mu acaba zaten fotoğrafları ihtiyacımız var ki ense ve kulak üstü bölgesini de görebilirim ki çok alabilecek miyiz karşılık alabileceğiz için yapabilecek miyiz saç ekim öyle sandığınız kadar basit bir işlem değil o yüzden sağlıklıdır doğru bilgi verebilmem için fotoğraf paylaşmanızı rica ederim tamam o zaman', 'İyi günler Saç Ekim Merkezi Öykü olmaya başladı Ben kafamda böyle kirletilen çıkmaya başladı bu sefer kulak üstü ve ense bölgesinden resimlerini çekip paylaşın ona göre detaylı Bir analiz yapıp sizi bilgilendiririm oluyor Tamam Tamam bekliyorum Görüşmek üzere Rica ederim', 'Alo Alo Selamünaleyküm Aleykümselam Kutlay Kutlay']\n"
          ]
        }
      ],
      "source": [
        "#@title audio to text (Turkish)\n",
        "!pip install SpeechRecognition requests\n",
        "!pip install pydub\n",
        "import os\n",
        "import requests\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to download an audio file from a URL\n",
        "def download_audio_from_url(url, destination_path):\n",
        "    response = requests.get(url)\n",
        "    with open(destination_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "# Function to convert audio file to text\n",
        "def convert_audio_to_text(file_path, language='tr-TR'):\n",
        "    # Initialize the recognizer\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    # Load the audio file\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        # Read the audio data from the file\n",
        "        audio_data = r.record(source)\n",
        "\n",
        "        # Perform speech recognition\n",
        "        text = r.recognize_google(audio_data, language=language)\n",
        "\n",
        "        return text\n",
        "\n",
        "# Function to convert a list of audio files to text\n",
        "def convert_audio_list_to_text(file_list, language='tr-TR'):\n",
        "    texts = []\n",
        "    for file_path in file_list:\n",
        "        text = convert_audio_to_text(file_path, language)\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# List of MP3 files URLs\n",
        "mp3_files = list_tur\n",
        "\n",
        "turkish_files = []\n",
        "\n",
        "# Create a directory to save the downloaded files\n",
        "os.makedirs('audio_files', exist_ok=True)\n",
        "\n",
        "# Download the MP3 files\n",
        "downloaded_files = []\n",
        "for index, url in enumerate(mp3_files):\n",
        "    file_path = f'audio_files/audio{index+1}.mp3'\n",
        "    download_audio_from_url(url, file_path)\n",
        "    downloaded_files.append(file_path)\n",
        "\n",
        "# Convert MP3 files to WAV format\n",
        "wav_files = []\n",
        "for index, file_path in enumerate(downloaded_files):\n",
        "    wav_path = f'audio_files/audio{index+1}.wav'\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    audio.export(wav_path, format='wav')\n",
        "    wav_files.append(wav_path)\n",
        "\n",
        "# Convert WAV files to text\n",
        "transcriptions = convert_audio_list_to_text(wav_files, language='tr-TR')\n",
        "\n",
        "# Print the transcriptions\n",
        "for index, transcription in enumerate(transcriptions):\n",
        "    #print(f'Transcription {index+1}: {transcription}')\n",
        "    turkish_files.append(transcription)\n",
        "print(turkish_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5uZloYLIeGP",
        "outputId": "91c07704-f748-47b6-99d1-99e82510ad9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: ['Hello hello, peace be upon you too. How are you doing? May Allah keep you well. My little brother, Rizwan, is recovering from surgery at Turkiana Hospital in Istanbul, Turkey. You contacted us from the website \"tajmeeli.com\" about a cosmetic procedure, right? I told you earlier that I\\'ll get back to you tomorrow, God willing. What you heard from us is true. The person who spoke with you was Mareena\\'s mall staff. I\\'ll send you everything on WhatsApp later, but I saw everything with my own eyes. Everything is okay, God willing. We\\'re in Istanbul\\'s European side, near Marina, if you know her. Everything is okay, and if you don\\'t have any medication for diabetes or high blood pressure, there won\\'t be any problem. You can return to Istanbul before Eid without any issues, God willing. Do you understand me well? Everything is A-Okay, you can save my number as Rizwan Turk. If we talk again, and you don\\'t recognize me, I\\'ll send you a picture. Thank you and goodbye.', \"Hello, peace be upon you. Do you have a problem that you want to discuss with me? I want to see your photos first before meeting you or your family. May I know your name, please? I'm 20 years old and my name is Jassem. Who are you asking for specifically? I'll try to send you the pictures once you confirm the details and if it's necessary, I'll share more information with you.\", \"Hello, peace be upon you. Regarding the issue of hair transplantation, cosmetic surgery, and dentistry, there is Turkana Hospital in Istanbul. I saw your Instagram page and noticed that you offer Hollywood smile procedures for celebrities. However, I didn't quite understand your message. Could you please tell me which month you are looking to have the procedure? It's possible to book an appointment after 7 months, according to the Ministry of Health regulations. The hospital has a comprehensive facility and experienced staff. You'll get excellent results and care. Welcome, my name is Ayman and I'm your brother.\"]\n"
          ]
        }
      ],
      "source": [
        "#@title chatgpt API (arabic)\n",
        "!pip install -q openai \n",
        "import openai\n",
        "openai.api_key = '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'\n",
        "\n",
        "clean_text = []\n",
        "#please correct dictation mistakes and delete unknown vocabs except turkeya and turkeyana\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"please translate it to the English : .\"},\n",
        "]\n",
        "\n",
        "for text in arabic_files:\n",
        "    if decoded:\n",
        "        messages.append({\"role\": \"user\", \"content\": text})\n",
        "\n",
        "        chat = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\", messages=messages\n",
        "        )\n",
        "\n",
        "        reply = chat.choices[0].message.content\n",
        "        clean_text.append(reply)\n",
        "\n",
        "print(f\"ChatGPT: {clean_text}\")\n",
        "messages.append({\"role\": \"assistant\", \"content\": clean_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFzxvAWdIobG",
        "outputId": "a5e51e22-6438-4da2-9fca-01849b454587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: [\"I think this is a meeting where you want to discuss regarding your All on 4 treatment with us, yes yes. Do you have something specific in mind or are you actually looking for concentration on what treatment plan would work better for you? Because Jo Bres, which is actually one completely solid implant, is very successful. So, I would like to have some more information coming in regarding the Jo that still holds health, but at the same time, to weigh in the pluses and minuses. I actually have the capabilities very, very, very big, actually treatments for All on 4 OK. And regarding the other health, you put your own well, yes? Call C yes? Coming to my think tank, thank you for that. Or would you like to compare different price options? So what you can do is, I suggest you send me the pictures and your case, then I am going to put those together and actually give you the full treatment plan for both Zygomatic and Strong. And then you can actually choose whichever one. Okay? So, I should send you pictures? Yes, if you have them, that would be better. Could you download them like that? I've sent you all the pictures in a PDF file. I prefer that. I'll actually send you a WhatsApp message if you want. The PDF file contains the pictures that you can look at. What's up and email? I've only received them by email, so you have to just transfer the files. If you like, I can communicate with you through WhatsApp for the moment. Okay? But the email will be from you, okay? Right, so do that and communication can be on WhatsApp. I have sent you both email and WhatsApp and I would like you to look at it. Was that okay? Thank you very much for that. Good day, thank you.\", \"there are still many mistakes and unclear sentences in this text. Here's my attempt at making it more readable:\\n\\nHello, this is Mehmet calling from Clinic Gu in Turkeyana. Are you considering a hair transplant for yourself or someone you know? I see that you are quite young. What seems to be the issue with your hair? Did you notice any changes since you were 20? Also, where are you from originally? Sometimes, moving to a different place or experiencing stress can affect hair growth. Do you have any chronic diseases or take any medication currently? Have you had any surgeries in the past? \\n\\nI apologize if my voice sounds unclear. Have you spoken to anyone at our clinic before? If not, when are you planning to come for the transplant? I can send you a message with more information about what to expect, and also give you an idea of what kind of pictures we need for the assessment. Thank you.\", \"I'm sorry, I cannot understand the meaning of this text as the sentences are disjointed and do not form a coherent passage. Please provide more context or specific instructions so I can assist you better.\"]\n"
          ]
        }
      ],
      "source": [
        "#@title chatgpt API (english)\n",
        "!pip install -q openai\n",
        "import openai\n",
        "openai.api_key = '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'\n",
        "trans_text = []\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"please correct dictation mistakes and delete unknown vocabs except turkeya and turkeyana : .\"},\n",
        "]\n",
        "\n",
        "for text in text_list:\n",
        "    if decoded:\n",
        "        messages.append({\"role\": \"user\", \"content\": text})\n",
        "\n",
        "        chat = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\", messages=messages\n",
        "        )\n",
        "\n",
        "        reply = chat.choices[0].message.content\n",
        "        trans_text.append(reply)\n",
        "\n",
        "print(f\"ChatGPT: {trans_text}\")\n",
        "messages.append({\"role\": \"assistant\", \"content\": trans_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu9lG_-eJ0gv",
        "outputId": "9c057352-a058-4eaa-976e-dd9805ac1af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: [\"Hello, I wonder if the line is clear. How does it work at 14 cm in the Tepe region? Let's analyze it accordingly if there is anything like that. I can provide more detailed information if you call me. Also, can I just take a photo from the front and send it? We need photos to see the back of the head and the area around the ears to understand if we can do it and what the outcome will be. Hair transplant is not as simple as you might think, so it's important to have accurate information. Therefore, I kindly request that you share photos. Okay, then.\", \"Hello, I wonder if my voice is coming through. How will the process take place in the central Tepe region which is 14 cm? Let's analyze it according to the situation. Call me and I will give you detailed information. Can I just take a front picture and send it? We need photos so that I can see the back and above the ears and determine if we are able to proceed with the treatment. Hair transplantation is not a simple process as is commonly thought, so please share a picture for me to provide accurate information. Thank you, looking forward to hearing from you.\", 'Hello, hello. Peace be upon you. Upon you be peace. Kutlay, Kutlay.']\n"
          ]
        }
      ],
      "source": [
        "#@title chatgpt API (turkish)\n",
        "!pip install -q openai\n",
        "import openai\n",
        "openai.api_key = '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'\n",
        "tur_text = []\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"please translate it to the English : .\"},\n",
        "]\n",
        "\n",
        "for text in turkish_files:\n",
        "    if decoded:\n",
        "        messages.append({\"role\": \"user\", \"content\": text})\n",
        "\n",
        "        chat = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\", messages=messages\n",
        "        )\n",
        "\n",
        "        reply = chat.choices[0].message.content\n",
        "        tur_text.append(reply)\n",
        "\n",
        "print(f\"ChatGPT: {tur_text}\")\n",
        "messages.append({\"role\": \"assistant\", \"content\": tur_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufgMT8NTKIVF",
        "outputId": "6250a743-481a-4ff1-e905-6aa0843d14aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Clean Text Emotions: ['Positive', 'Positive', 'Positive']\n",
            "Clean Text Compound Scores: [0.9764, 0.7536, 0.9595]\n",
            "Clean Text Positive Scores: [0.173, 0.143, 0.19]\n",
            "Clean Text Negative Scores: [0.015, 0.035, 0.0]\n",
            "Clean Text Neutral Scores: [0.812, 0.822, 0.81]\n",
            "\n",
            "Translated Text Emotions: ['Positive', 'Negative', 'Positive']\n",
            "Translated Text Compound Scores: [0.9972, -0.5514, 0.4215]\n",
            "Translated Text Positive Scores: [0.223, 0.046, 0.173]\n",
            "Translated Text Negative Scores: [0.0, 0.062, 0.097]\n",
            "Translated Text Neutral Scores: [0.777, 0.892, 0.73]\n",
            "\n",
            "Turkish Text Emotions: ['Positive', 'Positive', 'Positive']\n",
            "Turkish Text Compound Scores: [0.9159, 0.809, 0.7906]\n",
            "Turkish Text Positive Scores: [0.133, 0.081, 0.412]\n",
            "Turkish Text Negative Scores: [0.0, 0.0, 0.0]\n",
            "Turkish Text Neutral Scores: [0.867, 0.919, 0.588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def analyze_emotion(text):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    sentiment_scores = sid.polarity_scores(text)\n",
        "    \n",
        "    # Extracting the sentiment scores\n",
        "    compound_score = sentiment_scores['compound']\n",
        "    positive_score = sentiment_scores['pos']\n",
        "    negative_score = sentiment_scores['neg']\n",
        "    neutral_score = sentiment_scores['neu']\n",
        "    \n",
        "    # Determining the emotion based on sentiment scores\n",
        "    if compound_score >= 0.05:\n",
        "        emotion = 'Positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        emotion = 'Negative'\n",
        "    else:\n",
        "        emotion = 'Neutral'\n",
        "    \n",
        "    return emotion, compound_score, positive_score, negative_score, neutral_score\n",
        "\n",
        "def analyze_emotion_lists(clean_text, trans_text, tur_text):\n",
        "    clean_emotions = []\n",
        "    trans_emotions = []\n",
        "    tur_emotions = []\n",
        "    clean_compound_scores = []\n",
        "    trans_compound_scores = []\n",
        "    tur_compound_scores = []\n",
        "    clean_positive_scores = []\n",
        "    trans_positive_scores = []\n",
        "    tur_positive_scores = []\n",
        "    clean_negative_scores = []\n",
        "    trans_negative_scores = []\n",
        "    tur_negative_scores = []\n",
        "    clean_neutral_scores = []\n",
        "    trans_neutral_scores = []\n",
        "    tur_neutral_scores = []\n",
        "    \n",
        "    # Analyze emotions and sentiment scores for clean_text\n",
        "    for text in clean_text:\n",
        "        emotion, compound_score, positive_score, negative_score, neutral_score = analyze_emotion(text)\n",
        "        clean_emotions.append(emotion)\n",
        "        clean_compound_scores.append(compound_score)\n",
        "        clean_positive_scores.append(positive_score)\n",
        "        clean_negative_scores.append(negative_score)\n",
        "        clean_neutral_scores.append(neutral_score)\n",
        "    \n",
        "    # Analyze emotions and sentiment scores for trans_text\n",
        "    for text in trans_text:\n",
        "        emotion, compound_score, positive_score, negative_score, neutral_score = analyze_emotion(text)\n",
        "        trans_emotions.append(emotion)\n",
        "        trans_compound_scores.append(compound_score)\n",
        "        trans_positive_scores.append(positive_score)\n",
        "        trans_negative_scores.append(negative_score)\n",
        "        trans_neutral_scores.append(neutral_score)\n",
        "\n",
        "    # Analyze emotions and sentiment scores for tur_text\n",
        "    for text in tur_text:\n",
        "        emotion, compound_score, positive_score, negative_score, neutral_score = analyze_emotion(text)\n",
        "        tur_emotions.append(emotion)\n",
        "        tur_compound_scores.append(compound_score)\n",
        "        tur_positive_scores.append(positive_score)\n",
        "        tur_negative_scores.append(negative_score)\n",
        "        tur_neutral_scores.append(neutral_score)\n",
        "    \n",
        "    return (clean_emotions, clean_compound_scores, clean_positive_scores, clean_negative_scores, clean_neutral_scores), \\\n",
        "           (trans_emotions, trans_compound_scores, trans_positive_scores, trans_negative_scores, trans_neutral_scores), \\\n",
        "           (tur_emotions, tur_compound_scores, tur_positive_scores, tur_negative_scores, tur_neutral_scores)\n",
        "\n",
        "(clean_emotions, clean_compound_scores, clean_positive_scores, clean_negative_scores, clean_neutral_scores), \\\n",
        "(trans_emotions, trans_compound_scores, trans_positive_scores, trans_negative_scores, trans_neutral_scores), \\\n",
        "(tur_emotions, tur_compound_scores, tur_positive_scores, tur_negative_scores, tur_neutral_scores) = analyze_emotion_lists(clean_text, trans_text, tur_text)\n",
        "\n",
        "print(f\"Clean Text Emotions: {clean_emotions}\")\n",
        "print(f\"Clean Text Compound Scores: {clean_compound_scores}\")\n",
        "print(f\"Clean Text Positive Scores: {clean_positive_scores}\")\n",
        "print(f\"Clean Text Negative Scores: {clean_negative_scores}\")\n",
        "print(f\"Clean Text Neutral Scores: {clean_neutral_scores}\")\n",
        "print()\n",
        "print(f\"Translated Text Emotions: {trans_emotions}\")\n",
        "print(f\"Translated Text Compound Scores: {trans_compound_scores}\")\n",
        "print(f\"Translated Text Positive Scores: {trans_positive_scores}\")\n",
        "print(f\"Translated Text Negative Scores: {trans_negative_scores}\")\n",
        "print(f\"Translated Text Neutral Scores: {trans_neutral_scores}\")\n",
        "print()\n",
        "print(f\"Turkish Text Emotions: {tur_emotions}\")\n",
        "print(f\"Turkish Text Compound Scores: {tur_compound_scores}\")\n",
        "print(f\"Turkish Text Positive Scores: {tur_positive_scores}\")\n",
        "print(f\"Turkish Text Negative Scores: {tur_negative_scores}\")\n",
        "print(f\"Turkish Text Neutral Scores: {tur_neutral_scores}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQeW-Cg2E4ne",
        "outputId": "c5d2f3d7-6e57-433f-f17c-b94da2434417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EN', 'EN', 'EN', 'AR', 'AR', 'AR', 'TR', 'TR', 'TR']\n",
            "['zcrm_1928433000860261621', 'zcrm_1928433000857205263', 'zcrm_1928433000854862161', 'zcrm_1928433001077811279', 'zcrm_1928433001081505357', 'zcrm_1928433001101605243', 'zcrm_1928433001091243284', 'zcrm_1928433001090019805', 'zcrm_1928433001089674201']\n",
            "[\"think this is a mean i'm you from of can clin regard in your al qui with us yes yes or i want you actually qu you have something specific in the mind or you actually have fu concentitation go what treatment plan work better like to because jo bres which actually one completely so want to like that for the s coming c plants say the the jo that still health but that same so to the in pl well i like actually have the c for ities very very very big actually treatments for for for jo ok and regard in the other health you put your on the well yes call c yes coming cs think king think for or want to comp see i actually one in plants don if you are the str plants or don'tknow just comm strong on plants so think about proble but other plants which got or factcess be be like work the b i can think well about difference any different brass but for the moment i my know is the the str on is option yes ct actually the strong is the best opt that exist in whole mar actually but bigigma it' quite and most people actually go to the ic ma because it's quite is different in the pr between strong and and migma for the single implants for the strong and is whatonce thousand for hundred other but in the migma the ger one of course ' course five hundred do so is a quite big differentdifference in those not the mig actually really good just a difference of of course the strong is way better than the midig course so and on your ud of course you know how many impl you need like for plants that like impl 's going to very big oun of different money the difference which between the strong and the migam it' going to be a very big difference ing so i i like to different upptions to have b to choose like the option for just come like price and the qual ity would like to to compare was differen in the price ok so can do is i s you misses so what's up some ach that we need from you ong that i have sent you the picture and your case then pend those 'm going es and can actually give the fu treatment pl for both igma strong and then you can actually choose ever which one or okay so i should you pictures yes if you have p actually that be better could you down ma like that i sen email this pictures because in the p d file is you pictures one file prefer sure i actually send you whats up msageif you want s the the and pict can or what's up and i got only on the byso have to just trans the f more i if you if like end you ma for for the moment to the email 'm going to do is i i ready you whats up it you for communicate but i ication ok ay but the email it will for in from you okay ictions ay right so do that and communication can what's up i have sent you both any and what'supand i would do you or you ta look look yes look it was pl you would you ach think you thank you much i for that good day think i\", \"lo even or have about your someor yeah you very much my name is mean 'm call you from clinic gu in trans so you qu in for the transant qu for yourself for some one that you know about me you right how you money nine see to be the problem with the because quite frly young have problem yeah just just for just grwn and i four whatever you all just just going and how all in since you al twent well you from or from ind here so you you well yeah so that actually maybe the reason because the change the whether area that you live maybe work maybe well work not have mean the is especially you know when you change the place you maybe some stress or lot and do you more good drink goation sometimes you have any chronic diseases or others you you me lo you ar me sorry problem my like that sound actually if you have any chronic other you you not have you any pre vious perations one question regard the help ple currently are you take in any medication you alth or sorry completely got you is and day have you been to talk you before you have not or right and when are you plan on come for trans much bab and february not let me just send you next ep messa for what going s actually icture give you idea how want pictures to be ta take it from okay or a good thank but\", \"yes good mor yes my name year yes you from your kind i yes numberber just and yes procedure you like to have like kind a okay know venty eight is i still have my but ro like yes and what ever cre you have may be i don't know what for the to for all my ok so need some phone of you te you have what what number another number i find you what' number we have what doctor formation would kind so you and some phone yes i can s you and exthree that i have and you have to lect to procedure that get body to the te okay i think ' yes i think ok and i can i can i can come december or this year or i can come next year i would i would need i would need log to have some phones of to come from what doctor and if you can end me pure like what now so to i ure be more eas you know i have exthree the and i s copy or to gr and s and then if it' not supicion do something that' time okay or right so what would be better i december or next year deceber whatever what for you like you need to what the doctor day and you will know okay and i'd like to know long the procedure is and to go and the course log oldso you and me or and dece okay is it easy to get from the a ok there do there to or number when an a want europe sideso i i d be f from your yes so i go to the youruroan side so for you i i know european side eas may be it' so have of there another or and little bit for okay so just s the picture to your number yes i yes receing your phone phone you for more ay thank you you what is your name love sp i you can call and okay that's gr son name yes can you put you name or what i and it just only you and what ok is my name is and there okay very good so i get today i think right is l l tomor or right know from thank you but\", 'الو الو السلام عليكم وعليكم السلام عليكم بالخير و لا خير ان شاء الله الله يخليك معك رضوان اخي الصغير طبي من مستشفى تركيانا اسطنبول تركيا يعني تواصلت معنا مش الموقع تجميليه دوت كوم انك مهتم عمليه تجميل صح هذا على الواتساب قلت له باكر ان شاء الله اقول لك يا عم صحيح صح من اللي شفته بعدنا صح اللي حكى معك صح والله اللي حكى معك مول مارينا انا راح ابعث لك كل شيء على الواتساب بعد لكن شفت بعيني و كل شيء ترى ان شاء الله تمام احنا في اسطنبول الاوروبيه مارينا يعني راح ابعث لك انا لو واحد لوريا اذا بتعرف عليها يعني احنا على البحر يعني بجانب المارينا 32 سنه 32 سنه العمر كله ان شاء الله وتعالى اذا قدر الله السكري ضغط الدم ما عندك ادويه صح ما في اي مشكله ما في اي مشكله وانت رحت ترجعي على اسطنبول ان شاء الله قبل العيد ان شاء الله ما في اي مشكله تمام تمام فهمت عليك ما في اي مشكله تمام انت سجل عندك رقمي باسم رضوان تركي انا مش اذا حكيت معك مره ثانيه ما تعرفني تمام تكون فاضي راح ابعث لك كيف تاخذ الصغار ابعث لك على الواتساب ان تاخذ الصور ابعث لي اياه ان شاء الله ان شاء الله شكرا كثير ومع السلامه مع السلامه', 'الو مرحبا السلام عليكم صار عندك بهمني عارف لحالي عشان اشوفهم واهلي اولا هو عمرك لو سمحت عايزين الاسم الكريم من فضلك عمري 20 سنه جاسم لخالد فارس فارس بدي اعرف ان شاء الله بس ان شاء الله ابعث لي الصور خليني اشوفك اذا ما هل العمليه والا بعطيك كل التفاصيل', 'الو الو السلام عليكم ورحمه الله وبركاته وعليكم السلام في موضوع زراعه الشعر والتجميل والاسنان مستشفى تركيانا اسطنبول والله انا شفت موقعكم انستغرام عندكم عشان اسوي تعديل المفاتيح لا تعمل عمليات اسنان هوليود سمايل في المشاهير لا والله انا عندي فكره ما فهمت عليك طيب اخوي بس شهر احنا بالميلادي لو تكرمت اي شهر ممكن يعني بعد 7 شهور وزاره الصحه من اكثر من 12 سنه مبنى متكامل بيت ام تركي ان شاء الله تحصل على نتائج ممتازه واشعار او اكثر حياك الله استاذ ايمن اسم حضرتك مضغوط اهلا وسهلا فيك وانا اخوك', 'Alo alo sesim geliyor mu acaba 14 cm ortama Tepe bölgesinde nasıl gerçekleşir var bir şey var yani ona göre bir analiz yapalım Siz arayıp detaylı bilgi vereyim ya zaten şey sadece ön taraftan bir tanem çeksem atsam olur mu acaba zaten fotoğrafları ihtiyacımız var ki ense ve kulak üstü bölgesini de görebilirim ki çok alabilecek miyiz karşılık alabileceğiz için yapabilecek miyiz saç ekim öyle sandığınız kadar basit bir işlem değil o yüzden sağlıklıdır doğru bilgi verebilmem için fotoğraf paylaşmanızı rica ederim tamam o zaman', 'İyi günler Saç Ekim Merkezi Öykü olmaya başladı Ben kafamda böyle kirletilen çıkmaya başladı bu sefer kulak üstü ve ense bölgesinden resimlerini çekip paylaşın ona göre detaylı Bir analiz yapıp sizi bilgilendiririm oluyor Tamam Tamam bekliyorum Görüşmek üzere Rica ederim', 'Alo Alo Selamünaleyküm Aleykümselam Kutlay Kutlay']\n",
            "[\"I think this is a meeting where you want to discuss regarding your All on 4 treatment with us, yes yes. Do you have something specific in mind or are you actually looking for concentration on what treatment plan would work better for you? Because Jo Bres, which is actually one completely solid implant, is very successful. So, I would like to have some more information coming in regarding the Jo that still holds health, but at the same time, to weigh in the pluses and minuses. I actually have the capabilities very, very, very big, actually treatments for All on 4 OK. And regarding the other health, you put your own well, yes? Call C yes? Coming to my think tank, thank you for that. Or would you like to compare different price options? So what you can do is, I suggest you send me the pictures and your case, then I am going to put those together and actually give you the full treatment plan for both Zygomatic and Strong. And then you can actually choose whichever one. Okay? So, I should send you pictures? Yes, if you have them, that would be better. Could you download them like that? I've sent you all the pictures in a PDF file. I prefer that. I'll actually send you a WhatsApp message if you want. The PDF file contains the pictures that you can look at. What's up and email? I've only received them by email, so you have to just transfer the files. If you like, I can communicate with you through WhatsApp for the moment. Okay? But the email will be from you, okay? Right, so do that and communication can be on WhatsApp. I have sent you both email and WhatsApp and I would like you to look at it. Was that okay? Thank you very much for that. Good day, thank you.\", \"there are still many mistakes and unclear sentences in this text. Here's my attempt at making it more readable:\\n\\nHello, this is Mehmet calling from Clinic Gu in Turkeyana. Are you considering a hair transplant for yourself or someone you know? I see that you are quite young. What seems to be the issue with your hair? Did you notice any changes since you were 20? Also, where are you from originally? Sometimes, moving to a different place or experiencing stress can affect hair growth. Do you have any chronic diseases or take any medication currently? Have you had any surgeries in the past? \\n\\nI apologize if my voice sounds unclear. Have you spoken to anyone at our clinic before? If not, when are you planning to come for the transplant? I can send you a message with more information about what to expect, and also give you an idea of what kind of pictures we need for the assessment. Thank you.\", \"I'm sorry, I cannot understand the meaning of this text as the sentences are disjointed and do not form a coherent passage. Please provide more context or specific instructions so I can assist you better.\", 'Hello hello, peace be upon you too. How are you doing? May Allah keep you well. My little brother, Rizwan, is recovering from surgery at Turkiana Hospital in Istanbul, Turkey. You contacted us from the website \"tajmeeli.com\" about a cosmetic procedure, right? I told you earlier that I\\'ll get back to you tomorrow, God willing. What you heard from us is true. The person who spoke with you was Mareena\\'s mall staff. I\\'ll send you everything on WhatsApp later, but I saw everything with my own eyes. Everything is okay, God willing. We\\'re in Istanbul\\'s European side, near Marina, if you know her. Everything is okay, and if you don\\'t have any medication for diabetes or high blood pressure, there won\\'t be any problem. You can return to Istanbul before Eid without any issues, God willing. Do you understand me well? Everything is A-Okay, you can save my number as Rizwan Turk. If we talk again, and you don\\'t recognize me, I\\'ll send you a picture. Thank you and goodbye.', \"Hello, peace be upon you. Do you have a problem that you want to discuss with me? I want to see your photos first before meeting you or your family. May I know your name, please? I'm 20 years old and my name is Jassem. Who are you asking for specifically? I'll try to send you the pictures once you confirm the details and if it's necessary, I'll share more information with you.\", \"Hello, peace be upon you. Regarding the issue of hair transplantation, cosmetic surgery, and dentistry, there is Turkana Hospital in Istanbul. I saw your Instagram page and noticed that you offer Hollywood smile procedures for celebrities. However, I didn't quite understand your message. Could you please tell me which month you are looking to have the procedure? It's possible to book an appointment after 7 months, according to the Ministry of Health regulations. The hospital has a comprehensive facility and experienced staff. You'll get excellent results and care. Welcome, my name is Ayman and I'm your brother.\", \"Hello, I wonder if the line is clear. How does it work at 14 cm in the Tepe region? Let's analyze it accordingly if there is anything like that. I can provide more detailed information if you call me. Also, can I just take a photo from the front and send it? We need photos to see the back of the head and the area around the ears to understand if we can do it and what the outcome will be. Hair transplant is not as simple as you might think, so it's important to have accurate information. Therefore, I kindly request that you share photos. Okay, then.\", \"Hello, I wonder if my voice is coming through. How will the process take place in the central Tepe region which is 14 cm? Let's analyze it according to the situation. Call me and I will give you detailed information. Can I just take a front picture and send it? We need photos so that I can see the back and above the ears and determine if we are able to proceed with the treatment. Hair transplantation is not a simple process as is commonly thought, so please share a picture for me to provide accurate information. Thank you, looking forward to hearing from you.\", 'Hello, hello. Peace be upon you. Upon you be peace. Kutlay, Kutlay.']\n",
            "['Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']\n",
            "[0.9764, 0.7536, 0.9595, 0.9972, -0.5514, 0.4215, 0.9159, 0.809, 0.7906]\n",
            "[0.015, 0.035, 0.0, 0.0, 0.062, 0.097, 0.0, 0.0, 0.0]\n",
            "[0.173, 0.143, 0.19, 0.223, 0.046, 0.173, 0.133, 0.081, 0.412]\n",
            "[0.812, 0.822, 0.81, 0.777, 0.892, 0.73, 0.867, 0.919, 0.588]\n"
          ]
        }
      ],
      "source": [
        "def process_call_ids(list_callids, list_call_duration, list_tr_call):\n",
        "    language_list = []\n",
        "    all_call_ids = []\n",
        "\n",
        "    for call_id in list_callids:\n",
        "        language_list.append('EN')\n",
        "        all_call_ids.append(call_id)\n",
        "\n",
        "    for call_id in list_call_duration:\n",
        "        language_list.append('AR')\n",
        "        all_call_ids.append(call_id)\n",
        "\n",
        "    for call_id in list_tr_call:\n",
        "        language_list.append('TR')\n",
        "        all_call_ids.append(call_id)\n",
        "\n",
        "    return language_list, all_call_ids\n",
        "language_list, all_call_ids = process_call_ids(list_callids, list_call_duration, list_tr_call)\n",
        "print(language_list)\n",
        "print(all_call_ids)\n",
        "\n",
        "def combine_lists(list1, list2, list3):\n",
        "    combined_original_text = []\n",
        "    combined_original_text.extend(list1)\n",
        "    combined_original_text.extend(list2)\n",
        "    combined_original_text.extend(list3)\n",
        "    return combined_original_text\n",
        "\n",
        "combined_original_text = combine_lists(text_list, arabic_files, turkish_files)\n",
        "print(combined_original_text)\n",
        "\n",
        "def combine_translate(list1, list2, list3):\n",
        "    combined_translated_text = []\n",
        "    combined_translated_text.extend(list1)\n",
        "    combined_translated_text.extend(list2)\n",
        "    combined_translated_text.extend(list3)\n",
        "    return combined_translated_text\n",
        "\n",
        "combined_translated_text = combine_translate(trans_text ,clean_text, tur_text)\n",
        "print(combined_translated_text)\n",
        "\n",
        "def combine_emotion(list1, list2, list3):\n",
        "    combined_emotion_text = []\n",
        "    combined_emotion_text.extend(list1)\n",
        "    combined_emotion_text.extend(list2)\n",
        "    combined_emotion_text.extend(list3)\n",
        "    return combined_emotion_text\n",
        "\n",
        "combined_emotion_text = combine_emotion(clean_emotions ,trans_emotions, tur_emotions)\n",
        "print(combined_emotion_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def combine_lists(list1, list2, list3):\n",
        "    combined_list = []\n",
        "    combined_list.extend(list1)\n",
        "    combined_list.extend(list2)\n",
        "    combined_list.extend(list3)\n",
        "    return combined_list\n",
        "\n",
        "def combine_compound(clean_compound_scores, trans_compound_scores, tur_compound_scores):\n",
        "    return combine_lists(clean_compound_scores, trans_compound_scores, tur_compound_scores)\n",
        "\n",
        "def combine_negative(clean_negative_scores, trans_negative_scores, tur_negative_scores):\n",
        "    return combine_lists(clean_negative_scores, trans_negative_scores, tur_negative_scores)\n",
        "\n",
        "def combine_positive(clean_positive_scores, trans_positive_scores, tur_positive_scores):\n",
        "    return combine_lists(clean_positive_scores, trans_positive_scores, tur_positive_scores)\n",
        "\n",
        "def combine_neutral(clean_neutral_scores, trans_neutral_scores, tur_neutral_scores):\n",
        "    return combine_lists(clean_neutral_scores, trans_neutral_scores, tur_neutral_scores)\n",
        "\n",
        "combined_compound_text = combine_compound(clean_compound_scores, trans_compound_scores, tur_compound_scores)\n",
        "print(combined_compound_text)\n",
        "\n",
        "combined_negative_text = combine_negative(clean_negative_scores, trans_negative_scores, tur_negative_scores)\n",
        "print(combined_negative_text)\n",
        "\n",
        "combined_positive_text = combine_positive(clean_positive_scores, trans_positive_scores, tur_positive_scores)\n",
        "print(combined_positive_text)\n",
        "\n",
        "combined_neutral_text = combine_neutral(clean_neutral_scores, trans_neutral_scores, tur_neutral_scores)\n",
        "print(combined_neutral_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz_Q6CUqqwO9",
        "outputId": "292b7302-7159-4317-e579-f49b43e290f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[], ['hair', 'Turkeyana', 'clinic', 'hair transplant', 'Turkey'], []], [['surgery', 'surgery', 'Turkey'], [], ['hair', 'surgery', 'hair transplant', 'surgery', 'smile']], [['head'], [], []]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# def find_keywords(keywords, text_lists):\n",
        "#     key_result = []\n",
        "#     for text_list in text_lists:\n",
        "#         sublist = []\n",
        "#         for text in text_list:\n",
        "#             found_keywords = [keyword for keyword in keywords if keyword in text]\n",
        "#             if found_keywords:\n",
        "#                 sublist.extend(found_keywords)\n",
        "#         key_result.append(sublist)\n",
        "#     return key_result\n",
        "\n",
        "# # Example usage\n",
        "# patterns = [\"hair\", \"head\", \"loss\", \"surgery\", \"Turkeyana\", \"clinic\", \"turkeyana clinic\", \"rhinoplasty\", \"botox\",\n",
        "#             \"under eye filler\", \"filler\", \"hair transplant\", \"breast\", \"tummy tuck\", \"liposuction\", \"sleeve\",\n",
        "#             \"teeth whitening\", \"teeth\", \"blepharoplasty\", \"face\", \"face lift\", \"invisalign\", \"limb lengthening\",\n",
        "#             \"surgery\", \"mesotherapy\", \"prp\", \"smile design\", \"smile\", \"skin care\", \"skincare\",\n",
        "#             \"non-surgical face lift\", \"non-surgical\", \"Turkey\", \"hair loss\"]\n",
        "\n",
        "# text_lists = [trans_text, clean_text, tur_text]\n",
        "\n",
        "# key_result = find_keywords(patterns, text_lists)\n",
        "# filtered_result = [item for item in key_result if item]\n",
        "# print(filtered_result)\n",
        "\n",
        "def find_keywords(keywords, text_lists):\n",
        "    key_result = []\n",
        "    for text_list in text_lists:\n",
        "        sublist = []\n",
        "        for text in text_list:\n",
        "            found_keywords = [keyword for keyword in keywords if keyword in text]\n",
        "            sublist.append(found_keywords)\n",
        "        key_result.append(sublist)\n",
        "    return key_result\n",
        "\n",
        "# Example usage\n",
        "patterns = [\"hair\", \"head\", \"loss\", \"surgery\", \"Turkeyana\", \"clinic\", \"turkeyana clinic\", \"rhinoplasty\", \"botox\",\n",
        "            \"under eye filler\", \"filler\", \"hair transplant\", \"breast\", \"tummy tuck\", \"liposuction\", \"sleeve\",\n",
        "            \"teeth whitening\", \"teeth\", \"blepharoplasty\", \"face\", \"face lift\", \"invisalign\", \"limb lengthening\",\n",
        "            \"surgery\", \"mesotherapy\", \"prp\", \"smile design\", \"smile\", \"skin care\", \"skincare\",\n",
        "            \"non-surgical face lift\", \"non-surgical\", \"Turkey\", \"hair loss\"]\n",
        "\n",
        "text_lists = [trans_text, clean_text, tur_text]\n",
        "\n",
        "key_result = find_keywords(patterns, text_lists)\n",
        "print(key_result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsuPp0AaKt9S",
        "outputId": "cd5a717c-859e-4025-d39e-8d6e49ce214b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    call_id  \\\n",
            "0  zcrm_1928433000860261621   \n",
            "1  zcrm_1928433000857205263   \n",
            "2  zcrm_1928433000854862161   \n",
            "3  zcrm_1928433001077811279   \n",
            "4  zcrm_1928433001081505357   \n",
            "5  zcrm_1928433001101605243   \n",
            "6  zcrm_1928433001091243284   \n",
            "7  zcrm_1928433001090019805   \n",
            "8  zcrm_1928433001089674201   \n",
            "\n",
            "                                       original_text  \\\n",
            "0  think this is a mean i'm you from of can clin ...   \n",
            "1  lo even or have about your someor yeah you ver...   \n",
            "2  yes good mor yes my name year yes you from you...   \n",
            "3  الو الو السلام عليكم وعليكم السلام عليكم بالخي...   \n",
            "4  الو مرحبا السلام عليكم صار عندك بهمني عارف لحا...   \n",
            "5  الو الو السلام عليكم ورحمه الله وبركاته وعليكم...   \n",
            "6  Alo alo sesim geliyor mu acaba 14 cm ortama Te...   \n",
            "7  İyi günler Saç Ekim Merkezi Öykü olmaya başlad...   \n",
            "8  Alo Alo Selamünaleyküm Aleykümselam Kutlay Kutlay   \n",
            "\n",
            "                                     translated_text original_language  \\\n",
            "0  I think this is a meeting where you want to di...                EN   \n",
            "1  there are still many mistakes and unclear sent...                EN   \n",
            "2  I'm sorry, I cannot understand the meaning of ...                EN   \n",
            "3  Hello hello, peace be upon you too. How are yo...                AR   \n",
            "4  Hello, peace be upon you. Do you have a proble...                AR   \n",
            "5  Hello, peace be upon you. Regarding the issue ...                AR   \n",
            "6  Hello, I wonder if the line is clear. How does...                TR   \n",
            "7  Hello, I wonder if my voice is coming through....                TR   \n",
            "8  Hello, hello. Peace be upon you. Upon you be p...                TR   \n",
            "\n",
            "    emotion  Compound_Scores  Positive_Scores  Negative_Scores  \\\n",
            "0  Positive           0.9764            0.173            0.015   \n",
            "1  Positive           0.7536            0.143            0.035   \n",
            "2  Positive           0.9595            0.190            0.000   \n",
            "3  Positive           0.9972            0.223            0.000   \n",
            "4  Negative          -0.5514            0.046            0.062   \n",
            "5  Positive           0.4215            0.173            0.097   \n",
            "6  Positive           0.9159            0.133            0.000   \n",
            "7  Positive           0.8090            0.081            0.000   \n",
            "8  Positive           0.7906            0.412            0.000   \n",
            "\n",
            "   Neutral_Scores                                          Keywords  \n",
            "0           0.812                                                    \n",
            "1           0.822  hair, Turkeyana, clinic, hair transplant, Turkey  \n",
            "2           0.810                                                    \n",
            "3           0.777                          surgery, surgery, Turkey  \n",
            "4           0.892                                                    \n",
            "5           0.730    hair, surgery, hair transplant, surgery, smile  \n",
            "6           0.867                                              head  \n",
            "7           0.919                                                    \n",
            "8           0.588                                                    \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# # Provide the column names\n",
        "# column_names = ['call_id', 'original_text', 'translated_text', 'original_language', 'emotion',\n",
        "#                 'Compound_Scores', 'Positive_Scores', 'Negative_Scores', 'Neutral_Scores']\n",
        "\n",
        "\n",
        "# # Determine the length of the longest list\n",
        "# max_length = max(len(all_call_ids), len(combined_original_text), len(combined_translated_text),\n",
        "#                  len(language_list), len(combined_emotion_text), len(combined_compound_text),\n",
        "#                  len(combined_positive_text), len(combined_negative_text), len(combined_neutral_text))\n",
        "\n",
        "# # Create a dictionary with the column names as keys and the corresponding lists as values\n",
        "# data_dict = {name: lst + [''] * (max_length - len(lst)) for name, lst in zip(column_names, [\n",
        "#     all_call_ids,\n",
        "#     combined_original_text,\n",
        "#     combined_translated_text,\n",
        "#     language_list,\n",
        "#     combined_emotion_text,\n",
        "#     combined_compound_text,\n",
        "#     combined_positive_text,\n",
        "#     combined_negative_text,\n",
        "#     combined_neutral_text\n",
        "# ])}\n",
        "\n",
        "# # Create the DataFrame\n",
        "# df_all = pd.DataFrame(data_dict)\n",
        "\n",
        "# print(df_all)\n",
        "import pandas as pd\n",
        "\n",
        "# Provide the column names\n",
        "column_names = ['call_id', 'original_text', 'translated_text', 'original_language', 'emotion',\n",
        "                'Compound_Scores', 'Positive_Scores', 'Negative_Scores', 'Neutral_Scores']\n",
        "\n",
        "# Determine the length of the longest list\n",
        "max_length = max(len(all_call_ids), len(combined_original_text), len(combined_translated_text),\n",
        "                 len(language_list), len(combined_emotion_text), len(combined_compound_text),\n",
        "                 len(combined_positive_text), len(combined_negative_text), len(combined_neutral_text))\n",
        "\n",
        "# Create a dictionary with the column names as keys and the corresponding lists as values\n",
        "data_dict = {name: lst + [''] * (max_length - len(lst)) for name, lst in zip(column_names, [\n",
        "    all_call_ids,\n",
        "    combined_original_text,\n",
        "    combined_translated_text,\n",
        "    language_list,\n",
        "    combined_emotion_text,\n",
        "    combined_compound_text,\n",
        "    combined_positive_text,\n",
        "    combined_negative_text,\n",
        "    combined_neutral_text\n",
        "])}\n",
        "\n",
        "# Create the DataFrame\n",
        "df_all = pd.DataFrame(data_dict)\n",
        "\n",
        "# Create a new column for Keywords and assign the items to the corresponding rows\n",
        "keywords_column = 'Keywords'\n",
        "df_all[keywords_column] = ''\n",
        "\n",
        "for i, keyword_list in enumerate(key_result):\n",
        "    keyword_values = [', '.join(sublist) for sublist in keyword_list]\n",
        "    for j, keyword_value in enumerate(keyword_values):\n",
        "        index = i * len(keyword_list) + j\n",
        "        df_all.at[index, keywords_column] = keyword_value\n",
        "\n",
        "print(df_all)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCu51i94LCr4",
        "outputId": "5d75e5f6-346b-42dc-f10c-c080f57d07ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Data saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# import pymysql\n",
        "# import pandas as pd\n",
        "\n",
        "# # Connection details\n",
        "# host = \"0.tcp.eu.ngrok.io\"\n",
        "# port = 12420\n",
        "# database = \"test\"\n",
        "# username = \"root\"\n",
        "# password = \"Elahe2023\"\n",
        "# table_name = \"your_table_name\"  # Replace with a suitable table name\n",
        "\n",
        "# # Connect to the database\n",
        "# cnx = pymysql.connect(user=username, password=password, host=host, port=port, database=database)\n",
        "# cnx.set_charset('utf8mb4')\n",
        "\n",
        "# # Assuming you have a DataFrame called 'df_subset' with the desired columns\n",
        "# df_subset = df_all[['call_id', 'original_text', 'translated_text', 'original_language', 'emotion', 'Compound_Scores', 'Positive_Scores', 'Negative_Scores', 'Neutral_Scores']]\n",
        "\n",
        "# # Create a cursor\n",
        "# cursor = cnx.cursor()\n",
        "\n",
        "# # Drop the existing table if it exists\n",
        "# drop_table_query = f\"DROP TABLE IF EXISTS {table_name}\"\n",
        "# cursor.execute(drop_table_query)\n",
        "\n",
        "# # Create a new table with the desired columns\n",
        "# create_table_query = f'''\n",
        "#     CREATE TABLE IF NOT EXISTS {table_name} (\n",
        "#         call_id VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         original_text VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         translated_text VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         original_language VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         emotion VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         Compound_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         Positive_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         Negative_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "#         Neutral_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\n",
        "#     )\n",
        "# '''\n",
        "# cursor.execute(create_table_query)\n",
        "\n",
        "# # Insert the data into the table\n",
        "# insert_query = f\"INSERT INTO {table_name} (call_id, original_text, translated_text, original_language, emotion, Compound_Scores, Positive_Scores, Negative_Scores, Neutral_Scores) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
        "\n",
        "# # Iterate over the rows of the DataFrame and insert the values\n",
        "# cursor.execute(\"SET NAMES utf8mb4\")\n",
        "\n",
        "# for index, row in df_subset.iterrows():\n",
        "#     values = (\n",
        "#         row['call_id'],\n",
        "#         row['original_text'], \n",
        "#         row['translated_text'],\n",
        "#         row['original_language'], \n",
        "#         row['emotion'], \n",
        "#         row['Compound_Scores'],\n",
        "#         row['Positive_Scores'],\n",
        "#         row['Negative_Scores'],\n",
        "#         row['Neutral_Scores']\n",
        "#     )\n",
        "#     cursor.execute(insert_query, values)\n",
        "\n",
        "# # Commit the changes and close the cursor and connection\n",
        "# cnx.commit()\n",
        "# cursor.close()\n",
        "# cnx.close()\n",
        "\n",
        "# print(\"Data saved successfully.\")\n",
        "!pip install pymysql\n",
        "import pymysql\n",
        "import pandas as pd\n",
        "\n",
        "# Connection details\n",
        "host = \"2.tcp.eu.ngrok.io\"\n",
        "port = 11971\n",
        "database = \"test\"\n",
        "username = \"root\"\n",
        "password = \"Elahe2023\"\n",
        "table_name = \"my_table2\"  # Replace with a suitable table name\n",
        "\n",
        "# Connect to the database\n",
        "cnx = pymysql.connect(user=username, password=password, host=host, port=port, database=database)\n",
        "cnx.set_charset('utf8mb4')\n",
        "\n",
        "# Assuming you have a DataFrame called 'df_subset' with the desired columns\n",
        "df_subset = df_all[['call_id', 'original_text', 'translated_text', 'original_language', 'emotion', 'Compound_Scores', 'Positive_Scores', 'Negative_Scores', 'Neutral_Scores','Keywords']]\n",
        "\n",
        "# Add a new column for Keywords\n",
        "# df_subset['Keywords'] = ''\n",
        "\n",
        "# Create a cursor\n",
        "cursor = cnx.cursor()\n",
        "\n",
        "# Drop the existing table if it exists\n",
        "drop_table_query = f\"DROP TABLE IF EXISTS {table_name}\"\n",
        "cursor.execute(drop_table_query)\n",
        "\n",
        "# Create a new table with the desired columns\n",
        "create_table_query = f'''\n",
        "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
        "        call_id VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        original_text VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        translated_text VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        original_language VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        emotion VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        Compound_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        Positive_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        Negative_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        Neutral_Scores VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
        "        Keywords VARCHAR(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\n",
        "    )\n",
        "'''\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Insert the data into the table\n",
        "insert_query = f\"INSERT INTO {table_name} (call_id, original_text, translated_text, original_language, emotion, Compound_Scores, Positive_Scores, Negative_Scores, Neutral_Scores, Keywords) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
        "\n",
        "# Iterate over the rows of the DataFrame and insert the values\n",
        "cursor.execute(\"SET NAMES utf8mb4\")\n",
        "\n",
        "for index, row in df_subset.iterrows():\n",
        "    values = (\n",
        "        row['call_id'],\n",
        "        row['original_text'], \n",
        "        row['translated_text'],\n",
        "        row['original_language'], \n",
        "        row['emotion'], \n",
        "        row['Compound_Scores'],\n",
        "        row['Positive_Scores'],\n",
        "        row['Negative_Scores'],\n",
        "        row['Neutral_Scores'],\n",
        "        row['Keywords']\n",
        "    )\n",
        "    cursor.execute(insert_query, values)\n",
        "\n",
        "# Commit the changes and close the cursor and connection\n",
        "cnx.commit()\n",
        "cursor.close()\n",
        "cnx.close()\n",
        "\n",
        "print(\"Data saved successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}